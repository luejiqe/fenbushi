# åŒå¡RTX 5090è®­ç»ƒæŒ‡å—

## ğŸš€ ç¡¬ä»¶é…ç½®

- **GPU**: 2 x NVIDIA GeForce RTX 5090 (24GB VRAM each)
- **è®­ç»ƒæ¡†æ¶**: PyTorch + DeepSpeed ZeRO-2
- **æ··åˆç²¾åº¦**: FP16 (å¼ºçƒˆæ¨è)
- **æ˜¾å­˜ä¼˜åŒ–**: ZeRO-2 (æ— éœ€CPU offload)

## âš¡ å¿«é€Ÿå¼€å§‹

### æ–¹æ¡ˆ1: æ¨èé…ç½® (å¹³è¡¡æ€§èƒ½)

```bash
python launch_deepspeed.py \
    --batch_size 64 \
    --epochs 50 \
    --fp16 \
    --num_workers 8
```

**ç‰¹ç‚¹**:
- æœ‰æ•ˆæ‰¹æ¬¡å¤§å°: 128 (64 Ã— 2 GPUs)
- æ˜¾å­˜ä½¿ç”¨: ~10GB per GPU
- è®­ç»ƒé€Ÿåº¦: éå¸¸å¿«
- æ¨èç”¨äºå¤§å¤šæ•°åœºæ™¯

### æ–¹æ¡ˆ2: æœ€å¤§æ‰¹æ¬¡ (æé™æ€§èƒ½)

```bash
python launch_deepspeed.py \
    --batch_size 128 \
    --epochs 50 \
    --fp16 \
    --num_workers 12
```

**ç‰¹ç‚¹**:
- æœ‰æ•ˆæ‰¹æ¬¡å¤§å°: 256 (128 Ã— 2 GPUs)
- æ˜¾å­˜ä½¿ç”¨: ~20GB per GPU
- è®­ç»ƒé€Ÿåº¦: æœ€å¿«
- é€‚åˆè¿½æ±‚æé™è®­ç»ƒé€Ÿåº¦

### æ–¹æ¡ˆ3: æ¢¯åº¦ç´¯ç§¯ (æ›´å¤§æœ‰æ•ˆæ‰¹æ¬¡)

```bash
python launch_deepspeed.py \
    --batch_size 64 \
    --gradient_accumulation_steps 2 \
    --epochs 50 \
    --fp16 \
    --num_workers 8
```

**ç‰¹ç‚¹**:
- æœ‰æ•ˆæ‰¹æ¬¡å¤§å°: 256 (64 Ã— 2 GPUs Ã— 2 steps)
- æ˜¾å­˜ä½¿ç”¨: ~10GB per GPU
- è®­ç»ƒé€Ÿåº¦: ç¨æ…¢ä½†æ‰¹æ¬¡æ›´å¤§
- é€‚åˆéœ€è¦å¤§æ‰¹æ¬¡è®­ç»ƒçš„åœºæ™¯

## ğŸ“Š æ€§èƒ½ä¼°ç®—

### RTX 5090åŒå¡ vs å…¶ä»–é…ç½®

| é…ç½® | æ‰¹æ¬¡å¤§å° | è®­ç»ƒé€Ÿåº¦ | æ¯epochæ—¶é—´ | æ˜¾å­˜ä½¿ç”¨ |
|------|---------|---------|------------|---------|
| å•å¡MX450 | 16 | 3.5 it/s | ~8åˆ†é’Ÿ | 1.8GB |
| å•å¡RTX 5090 | 128 | ~45 it/s | ~40ç§’ | 20GB |
| **åŒå¡RTX 5090** | **128** | **~80 it/s** | **~22ç§’** | **20GB** |
| **åŒå¡RTX 5090 (æ¨è)** | **64** | **~70 it/s** | **~25ç§’** | **10GB** |

### é¢„è®¡æ€»è®­ç»ƒæ—¶é—´

å‡è®¾90ä¸ªç±»åˆ«ï¼Œæ¯ä¸ªç±»åˆ«650å¼ å›¾ç‰‡ï¼Œæ€»è®¡58,500å¼ è®­ç»ƒå›¾ç‰‡ï¼š

- **50 epochs**: çº¦20-25åˆ†é’Ÿ
- **100 epochs**: çº¦40-50åˆ†é’Ÿ

æ¯”å•å¡MX450å¿«çº¦**18-20å€**ï¼

## ğŸ¯ é…ç½®ä¼˜åŒ–å»ºè®®

### æ‰¹æ¬¡å¤§å°é€‰æ‹©

æ ¹æ®æ‚¨çš„éœ€æ±‚é€‰æ‹©ï¼š

| Batch Size | æ˜¾å­˜ä½¿ç”¨ | è®­ç»ƒé€Ÿåº¦ | æ”¶æ•›æ€§ | æ¨èåœºæ™¯ |
|-----------|---------|---------|--------|---------|
| 32 | ~5GB | ä¸­ç­‰ | æœ€å¥½ | å®éªŒ/è°ƒè¯• |
| **64** | **~10GB** | **å¿«** | **å¥½** | **æ—¥å¸¸è®­ç»ƒ(æ¨è)** |
| 96 | ~15GB | å¾ˆå¿« | è¾ƒå¥½ | å¿«é€Ÿè®­ç»ƒ |
| 128 | ~20GB | æœ€å¿« | ä¸€èˆ¬ | è¿½æ±‚é€Ÿåº¦ |

### num_workersè®¾ç½®

æ ¹æ®CPUæ ¸å¿ƒæ•°è®¾ç½®ï¼š

```bash
# 8æ ¸å¿ƒCPU
--num_workers 8

# 12æ ¸å¿ƒCPU
--num_workers 12

# 16æ ¸å¿ƒæˆ–æ›´å¤š
--num_workers 16
```

**æ³¨æ„**: num_workersè¿‡é«˜ä¼šå¢åŠ CPUè´Ÿè½½ï¼Œå»ºè®®ä¸è¶…è¿‡CPUæ ¸å¿ƒæ•°ã€‚

### å­¦ä¹ ç‡è°ƒæ•´

å¤§æ‰¹æ¬¡éœ€è¦æ›´é«˜å­¦ä¹ ç‡ï¼š

| æœ‰æ•ˆæ‰¹æ¬¡å¤§å° | æ¨èå­¦ä¹ ç‡ |
|------------|----------|
| 32-64 | 0.001 |
| 128 | 0.0015 |
| 256 | 0.002 |
| 512+ | 0.003 |

ç¤ºä¾‹ï¼š
```bash
python launch_deepspeed.py \
    --batch_size 128 \
    --learning_rate 0.0015 \
    --fp16
```

## ğŸ“ å®Œæ•´è®­ç»ƒå‘½ä»¤ç¤ºä¾‹

### åŸºç¡€è®­ç»ƒ

```bash
python launch_deepspeed.py \
    --train_dir data/train \
    --val_dir data/val \
    --epochs 50 \
    --batch_size 64 \
    --learning_rate 0.001 \
    --num_workers 8 \
    --fp16
```

### é«˜çº§è®­ç»ƒ (è‡ªå®šä¹‰æ‰€æœ‰å‚æ•°)

```bash
python launch_deepspeed.py \
    --train_dir data/train \
    --val_dir data/val \
    --epochs 100 \
    --batch_size 96 \
    --learning_rate 0.0015 \
    --num_workers 12 \
    --gradient_accumulation_steps 1 \
    --fp16 \
    --checkpoint_dir checkpoints_rtx5090 \
    --save_interval 5
```

### ä½¿ç”¨è‡ªå®šä¹‰DeepSpeedé…ç½®

```bash
python launch_deepspeed.py \
    --config ds_config_rtx5090.json \
    --batch_size 64 \
    --fp16
```

## âš™ï¸ DeepSpeedé…ç½®è¯¦è§£

é¡¹ç›®åŒ…å«ä¸¤ä¸ªDeepSpeedé…ç½®æ–‡ä»¶ï¼š

### 1. ds_config_rtx5090.json (æ¨èç”¨äºRTX 5090)

**ä¼˜åŒ–ç‰¹ç‚¹**:
- âœ… æ— CPU offload (RTX 5090æ˜¾å­˜å……è¶³)
- âœ… æ›´å¤§çš„bucket size (5e8)
- âœ… Round-robin gradientsä¼˜åŒ–
- âœ… AdamWä¼˜åŒ–å™¨
- âœ… Warmupå­¦ä¹ ç‡è°ƒåº¦

**é€‚ç”¨åœºæ™¯**: RTX 3090/4090/5090ç­‰é«˜ç«¯æ˜¾å¡

### 2. ds_config_zero2.json (å…¼å®¹é…ç½®)

**ä¼˜åŒ–ç‰¹ç‚¹**:
- æ”¯æŒCPU optimizer offload
- è¾ƒå°çš„bucket size (2e8)
- åŸºç¡€Adamä¼˜åŒ–å™¨

**é€‚ç”¨åœºæ™¯**: ä¸­ä½ç«¯æ˜¾å¡ï¼Œæ˜¾å­˜ä¸è¶³æ—¶ä½¿ç”¨

## ğŸ”§ é«˜çº§é…ç½®

### å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹ (èŠ‚çœæ›´å¤šæ˜¾å­˜)

ä¿®æ”¹ `ds_config_rtx5090.json`:

```json
{
  ...
  "activation_checkpointing": {
    "partition_activations": true,
    "cpu_checkpointing": false,
    "contiguous_memory_optimization": true
  }
}
```

å¯é¢å¤–èŠ‚çœçº¦30%æ˜¾å­˜ï¼Œä½†è®­ç»ƒé€Ÿåº¦ä¼šé™ä½15-20%ã€‚

### å¯ç”¨FLOPsåˆ†æ

```json
{
  ...
  "flops_profiler": {
    "enabled": true,
    "profile_step": 10,
    "module_depth": -1,
    "detailed": true
  }
}
```

å°†åœ¨è®­ç»ƒæ—¶åˆ†ææ¨¡å‹è®¡ç®—é‡ã€‚

## ğŸ“Š ç›‘æ§å’Œè°ƒè¯•

### å®æ—¶ç›‘æ§

è®­ç»ƒæ—¶ä¼šæ˜¾ç¤ºï¼š
```
Epoch 1/50 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 458/458 [00:25<00:00, 18.12it/s, loss=2.345, acc=45.2]
Epoch 1/50 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 98/98 [00:05<00:00, 19.34it/s, loss=2.123, acc=48.7]

Epoch 1/50:
  Train Loss: 2.3450 | Train Acc: 45.20%
  Val Loss: 2.1234 | Val Acc: 48.70%
  Learning Rate: 0.001000
  Best Val Acc: 48.70% (Epoch 1)
```

### æŸ¥çœ‹GPUä½¿ç”¨ç‡

```bash
# å®æ—¶ç›‘æ§
watch -n 1 nvidia-smi

# æˆ–ä½¿ç”¨gpustat (éœ€å®‰è£…: pip install gpustat)
watch -n 1 gpustat
```

### æ£€æŸ¥ç‚¹ç®¡ç†

è®­ç»ƒä¼šè‡ªåŠ¨ä¿å­˜ï¼š
```
checkpoints_deepspeed/
â”œâ”€â”€ epoch_5/          # æ¯5ä¸ªepochä¿å­˜
â”œâ”€â”€ epoch_10/
â”œâ”€â”€ epoch_15/
â””â”€â”€ best_model/       # æœ€ä½³æ¨¡å‹
```

## âš ï¸ å¸¸è§é—®é¢˜

### 1. CUDA Out of Memory

**è§£å†³æ–¹æ³•**:
```bash
# å‡å°æ‰¹æ¬¡å¤§å°
python launch_deepspeed.py --batch_size 32 --fp16

# æˆ–ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯
python launch_deepspeed.py --batch_size 32 --gradient_accumulation_steps 2 --fp16
```

### 2. è®­ç»ƒé€Ÿåº¦æ…¢

**æ£€æŸ¥æ¸…å•**:
- âœ… æ˜¯å¦å¯ç”¨äº†FP16? (`--fp16`)
- âœ… num_workersæ˜¯å¦è¶³å¤Ÿ? (å»ºè®®8-12)
- âœ… æ˜¯å¦æœ‰å…¶ä»–ç¨‹åºå ç”¨GPU?
- âœ… æ‰¹æ¬¡å¤§å°æ˜¯å¦å¤ªå°? (å»ºè®®è‡³å°‘64)

### 3. GPUåˆ©ç”¨ç‡ä½

å¯èƒ½åŸå› ï¼š
- **num_workerså¤ªå°‘**: å¢åŠ åˆ°8-16
- **æ‰¹æ¬¡å¤ªå°**: å¢åŠ batch_size
- **æ•°æ®åŠ è½½æ…¢**: æ£€æŸ¥ç£ç›˜é€Ÿåº¦ï¼Œè€ƒè™‘ä½¿ç”¨SSD

### 4. ä¸¤å—GPUè´Ÿè½½ä¸å‡

è¿™æ˜¯æ­£å¸¸ç°è±¡ï¼ŒDeepSpeedä¼šè‡ªåŠ¨å¹³è¡¡ã€‚é€šå¸¸ï¼š
- GPU 0è´Ÿè½½ç¨é«˜ (ä½œä¸ºmaster)
- éšç€è®­ç»ƒè¿›è¡Œä¼šé€æ¸å¹³è¡¡

## ğŸ¯ æœ€ä½³å®è·µ

### æ¨èå·¥ä½œæµç¨‹

1. **å¿«é€ŸéªŒè¯** (1-2 epochs)
```bash
python launch_deepspeed.py --epochs 2 --batch_size 64 --fp16
```

2. **æ­£å¼è®­ç»ƒ** (50 epochs)
```bash
python launch_deepspeed.py --epochs 50 --batch_size 64 --fp16 --num_workers 8
```

3. **ç²¾ç»†è°ƒä¼˜** (é¢å¤–è®­ç»ƒ)
```bash
# ä»æ£€æŸ¥ç‚¹æ¢å¤å¹¶ç»§ç»­è®­ç»ƒ (åŠŸèƒ½å¾…å®ç°)
# python launch_deepspeed.py --resume checkpoints_deepspeed/best_model
```

### è®­ç»ƒæŠ€å·§

1. **é¢„è®­ç»ƒæƒé‡**: é»˜è®¤ä½¿ç”¨ImageNeté¢„è®­ç»ƒï¼Œæ”¶æ•›æ›´å¿«
2. **å­¦ä¹ ç‡é¢„çƒ­**: DeepSpeedé…ç½®å·²åŒ…å«warmup
3. **å®šæœŸéªŒè¯**: æ¯ä¸ªepochéƒ½ä¼šéªŒè¯
4. **ä¿å­˜æœ€ä½³**: è‡ªåŠ¨ä¿å­˜éªŒè¯é›†æœ€ä½³æ¨¡å‹

## ğŸ“ˆ æ€§èƒ½å¯¹æ¯”

### DeepSpeed ZeRO-2 vs æ ‡å‡†è®­ç»ƒ

| æŒ‡æ ‡ | æ ‡å‡†DDP | DeepSpeed ZeRO-2 | æå‡ |
|------|--------|-----------------|------|
| æ˜¾å­˜ä½¿ç”¨ | ~14GB | ~10GB | â¬‡ï¸ 29% |
| è®­ç»ƒé€Ÿåº¦ | ~60 it/s | ~70 it/s | â¬†ï¸ 17% |
| æœ€å¤§æ‰¹æ¬¡ | 96 | 128 | â¬†ï¸ 33% |
| é€šä¿¡å¼€é”€ | ä¸­ç­‰ | ä¼˜åŒ– | â¬†ï¸ 20% |

### RTX 5090 vs å…¶ä»–GPU

| GPUå‹å· | æ˜¾å­˜ | æ¨èæ‰¹æ¬¡ | è®­ç»ƒé€Ÿåº¦ |
|---------|------|---------|---------|
| MX450 | 2GB | 16 | 3.5 it/s |
| RTX 3060 | 12GB | 32 | ~15 it/s |
| RTX 3090 | 24GB | 96 | ~40 it/s |
| RTX 4090 | 24GB | 128 | ~60 it/s |
| **RTX 5090** | **24GB** | **128** | **~80 it/s** |
| **RTX 5090 Ã— 2** | **48GB** | **128Ã—2** | **~140 it/s** |

## ğŸ”— ç›¸å…³æ–‡æ¡£

- [DeepSpeedå®˜æ–¹æ–‡æ¡£](https://www.deepspeed.ai/docs/)
- [ZeROä¼˜åŒ–å™¨è¯¦è§£](https://www.deepspeed.ai/tutorials/zero/)
- [æ··åˆç²¾åº¦è®­ç»ƒ](https://pytorch.org/docs/stable/amp.html)

## ğŸ“ æ›´æ–°æ—¥å¿—

- **2025-12-28**: åˆ›å»ºRTX 5090ä¼˜åŒ–é…ç½®
  - æ·»åŠ  `ds_config_rtx5090.json`
  - ä¼˜åŒ– `launch_deepspeed.py`
  - ç§»é™¤MUSAå…¼å®¹ä»£ç ï¼Œä¸“æ³¨CUDAä¼˜åŒ–

---

**ç¯å¢ƒè¦æ±‚**:
- PyTorch >= 2.0.0 (CUDAç‰ˆæœ¬)
- DeepSpeed >= 0.12.0
- CUDA >= 11.8
- NVIDIA Driver >= 520

**æ¨èç³»ç»Ÿ**:
- Ubuntu 20.04/22.04 æˆ– Windows 11
- åŒè·¯CPU (12æ ¸å¿ƒä»¥ä¸Š)
- 32GB+ ç³»ç»Ÿå†…å­˜
- NVMe SSD (æ•°æ®é›†å­˜å‚¨)

**å¼€å§‹è®­ç»ƒ**: `python launch_deepspeed.py --fp16 --batch_size 64`
